{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae04757",
   "metadata": {},
   "source": [
    "# Demonstration Notebook\n",
    "This notebook is meant to produce a demo usage of the proposed Staged-aware learning framework. \n",
    "\n",
    "In this notebook, we will show the entire pipeline of fitting SAL, including calculating propensity scores and finding stage weights. Since the models will be based on neural networks, the performance will largely depend on the specifications of hyper-parameters (learning rate, hidden layers, activation functions, etc). To tune your own hyperparameters, please refer to the config.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61480339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import model\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CONFIG = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11647681",
   "metadata": {},
   "source": [
    "## Define a toy example:\n",
    "Training set:\n",
    "- X: [num_samples, num_stages, num_variables]\n",
    "- A: [num_samples, num_stages] \n",
    "- R: [num_samples]\n",
    "\n",
    "Note that in this demonstration example, the purely random assigned treatments are not related to the covariates or rewards. As a result, we don't expect the proposed methods will perform well. For well-selected examples, please refer to the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73271516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of sample, decision points, features\n",
    "n, T, v = 1000, 5, 20\n",
    "\n",
    "# set the random seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Randon Treatment assignments A_t ~ binom(0.5)\n",
    "A = torch.randint(0, 2, (n, T)) * 2 - 1\n",
    "\n",
    "# Define the rewards\n",
    "reward_beta = torch.randn(T, v)\n",
    "r = torch.zeros(n, T) # save the rewards\n",
    "\n",
    "# Define the underlying optimal treatment\n",
    "optimal_treatment_beta = torch.randn(T, v) # linear decision rule\n",
    "O = torch.zeros(n, T) # save the ground-true optimal treatments\n",
    "\n",
    "X = torch.randn(n, T, v)\n",
    "for t in range(1, T):\n",
    "    noise = torch.randn(n, v)\n",
    "    A0_noise, A1_noise = noise[A[:, t-1] == -1], noise[A[:, t-1] == 1]\n",
    "    X[A[:, t-1] == -1, t] = 0.6 * X[A[:, t-1] == -1, t-1] + 0.8 * A0_noise\n",
    "    X[A[:, t-1] == 1, t] = 0.8 * X[A[:, t-1] == 1, t-1] + 0.6 * A1_noise\n",
    "    # optimal decision\n",
    "    O[:,t] = torch.sign(X[:,t,:] @ optimal_treatment_beta[t,])\n",
    "    # immediate rewards\n",
    "    r[:,t] = (X[:,t,:] @ reward_beta[t,] + torch.randn(n)) / 10 + A[:,t] * O[:,t]\n",
    "\n",
    "R = r.sum(dim=1)\n",
    "\n",
    "idx = torch.randperm(n)\n",
    "train_size = int(n * 0.8)\n",
    "idxTr, idxTe = idx[:train_size], idx[train_size:]\n",
    "\n",
    "X, A, R, O = X.to(device), A.to(device), R.to(device), O.to(device)\n",
    "Xtr, Xte, Atr, Ate, Rtr, Rte = X[idxTr], X[idxTe], A[idxTr], A[idxTe], R[idxTr], R[idxTe]\n",
    "\n",
    "Otr, Ote = O[idxTr], O[idxTe]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb279c",
   "metadata": {},
   "source": [
    "## Calculate Propensity\n",
    "- Calculate the probability of each assignment at each stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c892c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (lr:    0.005000):  training-Loss: 4.873\n",
      "Epoch 50 (lr:    0.004268):  training-Loss: 4.814\n",
      "Epoch 100 (lr:    0.002500):  training-Loss: 4.783\n",
      "Epoch 150 (lr:    0.000732):  training-Loss: 4.800\n",
      "Epoch 200 (lr:    0.000000):  training-Loss: 4.796\n",
      "Epoch 250 (lr:    0.000732):  training-Loss: 4.786\n",
      "Train accuracy: 52.300%\n",
      "Train accuracy: 51.100%\n"
     ]
    }
   ],
   "source": [
    "propen = model.PropensityModel(v, T, CONFIG['propensity']['hidden_dim'], 48, device=device).to(device)\n",
    "model.trainNN(propen, Data.TensorDataset(Xtr, Atr), **CONFIG['propensity'])\n",
    "\n",
    "Ahat = (propen(X, A) > 0.5).long() * 2 - 1\n",
    "print(\"Train accuracy: %.3f%%\" % ((Ahat[idxTr] == A[idxTr]).float().mean().item() * 100))\n",
    "print(\"Train accuracy: %.3f%%\" % ((Ahat[idxTe] == A[idxTe]).float().mean().item() * 100))\n",
    "\n",
    "pi = propen.calculate_propensity(X, A)\n",
    "piTr, piTe = pi[idxTr], pi[idxTe]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73bad2",
   "metadata": {},
   "source": [
    "## Stage-Aware Learning (SAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6855566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (lr:    0.010000):  training-Loss: -21449.387\n",
      "Epoch 100 (lr:    0.005000):  training-Loss: -31547.859\n",
      "Epoch 200 (lr:    0.000000):  training-Loss: -31593.971\n",
      "Epoch 300 (lr:    0.005000):  training-Loss: -31939.652\n",
      "Epoch 400 (lr:    0.010000):  training-Loss: -33181.480\n",
      "Epoch 500 (lr:    0.005000):  training-Loss: -33629.250\n",
      "Epoch 600 (lr:    0.000000):  training-Loss: -33753.637\n",
      "Epoch 700 (lr:    0.005000):  training-Loss: -33859.547\n",
      "SAL training accuracy:  65.225%\n",
      "SAL testing accuracy:  62.200%\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(model)\n",
    "\n",
    "SAL = model.SALModel(v, T, CONFIG['SAL']['hidden_dim'], 48, device=device).to(device)\n",
    "model.trainNN(SAL, Data.TensorDataset(Xtr, Atr, Rtr, piTr), R_hat=Rtr.mean(), **CONFIG['SAL'])\n",
    "\n",
    "print(\"SAL training accuracy:  %.3f%%\" % ((SAL.predict(Xtr) == Otr).float().mean() * 100))\n",
    "print(\"SAL testing accuracy:  %.3f%%\" % ((SAL.predict(Xte) == Ote).float().mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5107225",
   "metadata": {},
   "source": [
    "### Stage-Weighted Learning (SWL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83c9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the stage weights model:\n",
      "Epoch 0 (lr:    0.001000):  training-Loss: 31.883\n",
      "Epoch 50 (lr:    0.000854):  training-Loss: 29.786\n",
      "Epoch 100 (lr:    0.000500):  training-Loss: 30.676\n",
      "Epoch 150 (lr:    0.000146):  training-Loss: 29.923\n",
      "Epoch 200 (lr:    0.000000):  training-Loss: 29.675\n",
      "Epoch 250 (lr:    0.000146):  training-Loss: 30.233\n",
      "Stage weights:   tensor([[0.2955, 0.1115, 0.1868, 0.2059, 0.2003]], device='cuda:0') \n",
      "\n",
      "Training SWL: \n",
      "Epoch 0 (lr:    0.010000):  training-Loss: -21552.664\n",
      "Epoch 100 (lr:    0.005000):  training-Loss: -30411.086\n",
      "Epoch 200 (lr:    0.000000):  training-Loss: -30524.781\n",
      "Epoch 300 (lr:    0.005000):  training-Loss: -30746.986\n",
      "Epoch 400 (lr:    0.010000):  training-Loss: -32101.652\n",
      "Epoch 500 (lr:    0.005000):  training-Loss: -32832.008\n",
      "Epoch 600 (lr:    0.000000):  training-Loss: -32903.707\n",
      "Epoch 700 (lr:    0.005000):  training-Loss: -33466.656\n",
      "SWL training accuracy:  64.325%\n",
      "SWL testing accuracy:  63.600%\n"
     ]
    }
   ],
   "source": [
    "# Calculate stage weights\n",
    "stage_weights_model = model.WeightNNModel(v, T, CONFIG['stage_weights']['hidden_dim'], 48, device=device).to(device)\n",
    "print(\"Training the stage weights model:\")\n",
    "model.trainNN(stage_weights_model, Data.TensorDataset(Xtr, Atr, Rtr), **CONFIG['stage_weights'])\n",
    "sw = stage_weights_model.getWeights()\n",
    "print(\"Stage weights:  \", sw, '\\n')\n",
    "\n",
    "# Fit SWL model\n",
    "SWL = model.SWLModel(v, T, CONFIG['SWL']['hidden_dim'], 48, device=device).to(device)\n",
    "print(\"Training SWL: \")\n",
    "model.trainNN(SWL, Data.TensorDataset(Xtr, Atr, Rtr, piTr), R_hat=Rtr.mean(), sw=sw, **CONFIG['SWL'])\n",
    "\n",
    "print(\"SWL training accuracy:  %.3f%%\" % ((SWL.predict(Xtr) == Otr).float().mean() * 100))\n",
    "print(\"SWL testing accuracy:  %.3f%%\" % ((SWL.predict(Xte) == Ote).float().mean() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
